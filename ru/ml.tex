\chapter{``Вкус'' ML}

В предыдущих главах мы начали с чистого $lambda$-исчисления, а затем
систематически расширяли его новыми возможностями.  Например, мы
добавили конструкцию `let' как примитив, чтобы сделать полиморфическое
типизирование более полезным, а также оператор рекурсии, для того,
чтобы восстановить мощь вычислений, которая была потеряна после
введения типов.  Двигаясь дальше по этому пути, мы в конечном счете
достигли ML, при этом имея возможность простого взгляда на мир
используя типизированное $lambda$-исчисление.

Следующей стадией является избавление от выражения таких типов данных
как логические значения и натуральные числа через $lambda$-термы, и
создания примитивов для них.  Так что мы получим новые примитивные
типы, такие как {\tt bool} и {\tt int} (положительные и отрицательные
целые числа) и новые конструктора типов, такие как $\times$,~--- шаг,
который мы пречувствовали в последней главе.  С этими изменениями
также связаны новые константы и новые правила преобразования.
Например, выражение $2 + 2$ вычисляется с использованием машинной
арифметики, вместо преобразования его в нумералы Черча и выполнения
$\beta$-преобразований.  Эти допольнительные преобразования,
рассматриваемые как расширение обычных $lambda$-операций, часто
называются `$\delta$-преобразованиями'.  Мы увидим в течении курса как
язык ML расширен по сравнению с чистым $lambda$-исчислением.  Первым
делом мы должны обратиться к фундаментальному вопросу стратегии оценки
выражений ML.

\section{Энергичное вычисление}

Мы сказали, что с теоретической точки зрения, нормальный порядок
(сверху вниз, слева направо) редукции выражений более предпочтителен,
поскольку, если любая стратегия завершается, то она и будет выбрана
(???this one will).\footnote{Эта стратегия подобна некоторым,
  используемым в традиционных языках, таких как Algol 60, где на нее
  ссылались как на {\em вызов по имени}.}  Однако, этот подход имеет
некоторые практические дефекты.  Например, рассмотрим следуюшее
выражение:

$$ (\lamb{x} x + x + x)\; (10 + 5) $$

При использовании нормального порядка редукции мы получаем $(10 + 5) +
(10 + 5) + (10 + 5)$, и на следующих шагах редукции мы должны
вычислить три отдельных вхождения (??? instances) одного и того же
выражения.  На практике это совершенно недопустимо.  Существует два
основных решения данной проблемы, эти решения делят мир
функционального программирования на два лагеря.

Первым решением является придерживание нормального порядка редукции,
но при этом пытаться оптимизовать реализацию так, чтобы множественные
подвыражения, возникающие при таком подходе, использовались совместно,
и никогда не вычислялись более одного раза.  Внутри выражения
представляются как связанные ацикличные графы, а не деревья.  Этот
подход известен как {\em ленивое (lazy)} или {\em вызов по
  необходимости (call-by-need)} вычисление, поскольку выражения
вычисляются только тогда, когда они необходимы.

Вторым решением является попытка перевернуть теоретические размышления
о стратегии редукции с ног на голову, и вычислять аргументы функции до
передачи значений.  Этот подход известен как {\em аппликативный
  порядок} или {\em энергичное} вычисление.  Последнее имя возникло
из-за того, что аргументы функции вычисляются даже тогда, когда они не
нужны, например, $t$ в $(\lamb{x} y)\; t$.  Конечно, энергичное
вычисление означает, что некоторые выражения могут зацикливаться,
тогда как они могут завершаться при работе в ленивом режиме.  Но это
считается допустими, поскольку этих вещей достаточно легко избежать на
практике.  В любом случае, стратегия энергичного вычисления является
стандартной для многих языков программирования, таких как C, где на
нее ссылаются как на {\em вызов по значению (call by value)}.

ML использует энергичное вычисление по двум основным причинам.
Управление редукцией и совместным использованием, которое возникает
при ленивом вычислении, является достаточно сложным, и реализация
может быть относительно неэффективной и усложненной.  Если программист
не особо заботлив, то память может заполниться невычисленными
выражениями, и в общем тяжело понять потребление памяти программами.
В действительности, многие реализации ленивого вычисления стараются
оптимизовать их, путем использования энергичных вычислений в тех
местах, где семантика не отличается.\footnote{Они стараются выполнить
  {\em анализ строгости}~--- один из видов статического анализа,
  который часто помогает определить, что аргументы должны быть
  вычислены \cite{mycroft-thesis}.}  В противоположность этому, в ML
мы всегда сначала вычисляем аргументы функций, и только затем
выполняем $\beta$-редукцию~--- это просто и эффективно, и легко
реализуется с использованием стандартных технологий построения
компиляторов.

Второй причиной для выбора аппликативного порядка вычислений является
то, что ML не является {\em чистым} функциональным языком, а имеет
императивные возможности (переменные, присваивание и т.п.).
Следовательно, порядок вычисления подвыражений может сделать {\em
  семантику} отличающейся, а не просто затрагивает эффективность.
Если используется ленивое вычисление, то для программиста становится
практически невозможным показать (в нетривиальной программе) когда
какое подвыражение вычисляется.  В энергичной системе ML, нужно лишь
помнить простое правило вычисления.

Однако важно осозновать, что стратегия вычислений ML  {\em не} просто
снизу-вверх, в противоположность нормальному порядку редукции. В
действительности ML {\em никогда не вычисляет содержимое
  $lambda$-выражений}.  (В частности, он не когда не
редуцирует$\eta$-???redexes, в только $\beta$-???redexes.)  При
вычислении  $(\lamb{x} s[x])\; t$, сначала вычисляется $t$.  Однако
$s[x]$ не затрагивается, поскольку оно является содержимым
$lambda$-выражения.  Кроме того, любое подвыражение  $t$, которое
является содержимым $lambda$-выражения, также остается нетронутым.
Вот точные правила вычисления:

\begin{itemize}

\item Константы вычисляются сами в себя.

\item Вычисления заканчиваются на $\lambda$-абстракциях, и не
  затрагивают их содержимого.  В частности, не выполняется
  $\eta$-преобразование.

\item При вычислении комбинации $s\; t$ {\em сначала} вычисляются и
  $s$ и $t$. Предполагая, что вычисляемая форма $s$ является
  $lambda$-абстракцией, то выполняется $\beta$-преобразование верхнего
  уровня, и процесс повторяется.

\end{itemize}

Порядок вычисления $s$ и $t$ отличается в зависимости от версии ML.  В
той версии, которую мы будем использовать, сначала всегда
вычисляется~$t$.  Строго говоря, мы также должны задать правило для
{\tt let}-выражений, поскольку, как упоминалось, они теперь
рассматриваются как примитивы.  Однако, с точки зрения вычислений, они
могут рассматриваться как обычно, как $lambda$-выражения, примененные
к аргументу, с понимаем того, что  rand???? будет вычислен первым.
Для того, чтобы сделать это явным, правило для 

$$ \mbox{let}\; x = s\; \mbox{in}\; t $$

\noindent гласит, что сначала вычисляются все $s$, а результат
подставляется вместо $x$ в $t$, и в заключение, вычисляется новое
значение $t$.  Давайте рассмотрим некоторые примеры вычисления
выражений:

\begin{eqnarray*}
(\lamb{x} (\lamb{y} y + y)\; x) (2 + 2)
& \goesto & (\lamb{x} (\lamb{y} y + y)\; x) 4   \\
& \goesto & (\lamb{y} y + y) 4                  \\
& \goesto & 4 + 4                               \\
& \goesto & 8
\end{eqnarray*}

Заметьте, что подтерм $(\lamb{y} y + y)\; x$ is {\em не редуцируется},
поскольку он находится внутри $lambda$-выражения.  Однако,
что редуцируемые термы, \emph{не} находящиеся внутри $lambda$-выражений
обоих функций, а также аргумент, редуцируются до того, как вычисляется
применения функции, например, второй шаг будет следующим:

\begin{eqnarray*}
((\lamb{f\; x} f\; x)\; (\lamb{y} y + y))\; (2 + 2)
& \goesto & ((\lamb{f\; x} f\; x)\; (\lamb{y} y + y))\; 4           \\
& \goesto & (\lamb{x} (\lamb{y} y + y)\; x)\; 4                   \\
& \goesto & (\lamb{y} y + y)\; 4                                  \\
& \goesto & 4 + 4
\end{eqnarray*}

Факт, что ML не вычисляет внутри $lambda$-выражений, является ключевым
для высококвалифицированных программистов на ML.  Это дает возможность
точного контроля за вычислением выражений, и может использоваться для
имитации многих полезных вещей из стратегии ленивого вычисления.  Мы
увидим очень простые примеры в следующем разделе.

\section{Результаты энергичного вычисления}

Использование энергичного вычисления заставляет нас объявить некоторые
дополнительные возможности как примитивы, с их собственными
специальными процедурами редукции, вместо того, чтобы реализовать их
напрямую, в терминах $lambda$-исчисления.  В частности, мы не можем
больше рассматривать условную конструкцию:

$$ \mbox{if}\; b\; \mbox{then}\; e_1\; \mbox{else}\; e_2 $$

\noindent как применение обычного трехкомпонентного (тернарного) оператора:

$$ \mbox{COND}\; b\; e_1\; e_2 $$

Причина заключается в том, что в любом случае, из-за применения
энергичного вычисления, мы вычисляем все выражения $b$, $e_1$ и $e_2$,
\emph{до} вычисления содержимого $\mbox{COND}$.  Обычно это пагубно.
Например, заново рассмотрим наше определение функции для вычисления
факториала:

$$ \mbox{let rec fact}(n) = \mbox{if ISZERO}\; n\; \mbox{then}\; 1\;
                            \mbox{else}\; n * \mbox{fact}(\mbox{PRE}\; n) $$

Если условие будет вычислять все свои аргументы, то для вычисления 
$\mbox{fact}(0)$, ветвь `else' также должна быть вычислена, что
в свою очередь вызывает вычисление $\mbox{fact}(\mbox{PRE}\; 0)$.  И
это в свою очередь вызывает вычисление $\mbox{fact}(\mbox{PRE}\;
(\mbox{PRE}\; 0))$, и т.д.  Соответственно, вычисление превратиться в
бесконечный цикл.

Таким образом, мы делаем условия примитивной конструкцией, и изменяем
обычную стратегию редукции таким образом, что  {\em сначала}
вычисляется логическое выражение, а затем вычисляется {\em только
  одно} из двух ветвей условия.

А что происходит с самим процессом рекурсии?  Мы предполагаем
понимание рекурсивных определений в терминах рекурсивного оператора
$Rec$ с его собственным правилом редукции:

$$ Rec\; f \goesto f(Rec\; f) $$

\noindent он также будет зацикливаться при использовании стратегии
энергичного вычисления:

$$  Rec\; f \goesto f(Rec\; f) \goesto f(f(Rec\; f)) \goesto f(f(f(Rec\; f)))
\goesto \cdots $$

Однако, нам необходимо лишь очень простое изменение в правиле
редукции, которое заставит работать правильно:

$$ Rec\; f \goesto f(\lamb{x} Rec\; f\; x) $$

Теперь, $lambda$-выражение справа означает, что $\lamb{x} Rec\; f\; x$
вычисляется само в себя, и только после того, как выражение будет
редуцирует следующие подстановки в теле $f$, вычисление продолжится.

\section{Семейство языков ML}

Мы говорили о `ML' так, как будто это один язык.  На самом деле
существует много вариантов ML, даже включая `Lazy ML', реализацию
университета Chalmers в Швеции, которая базируется на ленивых
вычислениях.  Наиболее популярная версия ML в образовании~--- это
`Standard ML', но мы будет использовать другую версию, называющуюся
CAML (`camel') Light.\footnote{Это имя означает `Categorical Abstract
  Machine', метод реализации, лежащий в ее основе.}  Мы выбрали CAML
Light по следующим причинам:

\begin{itemize}

\item реализация имеет небольшой объем и хорошо переносима между
  платформами, так что она эффективно работает на Unix, PC, Macs, и
  других.

\item Система очень проста, синтаксически и семантически, что делает
  ее достаточно простой для изучения.

\item Система хорошо подходит для практического использования,
  например, она имеет интерфейс с библиотекам на языке C и
  поддерживает стандартную, раздельную компиляцию, совместимую с {\tt
    make}.

\end{itemize}

Однако, мы будем изучать достаточно общие техники, и любой написанный
код, может быть запущен (с небольшими синтаксическими изменениями) на
любой версии ML, и часто, на других функциональных языках.

\section{Запуск ML}

ML уже установлен на рабочий сервер (Thor).  Для того, чтобы
использовать его, вам необходимо поместить каталог с исполняемыми
файлами CAML в переменную среды {\tt PATH}.  Это может быть сделано
следующим образом (преполагая, что вы используете командный процессор
`bash' или что-то из его семейства):

\begin{boxed}\begin{verbatim}
  PATH="$PATH:/home/jrh13/caml/bin"
  export PATH
\end{verbatim}\end{boxed}%$

Чтобы не вводить эти команды при каждом заходе на сервер, вы можете
вставить эти команды в конец вашего файла {\tt .bash\_profile}, или
его эквивалента для вашего командного процессора.  Теперь, для
использования CAML в интерактивном режиме, вам просто надо набрать
{\tt camllight}, и программа должна запуститься и выдать приглашение
(`{\tt \#}'):

\begin{boxed}\begin{verbatim}
  $ camllight
  >       Caml Light version 0.73

  #
\end{verbatim}\end{boxed}%$

Для того, чтобы выйти из системы, просто наберите {\tt ctrl/d} или
{\tt quit();;} в строке приглашения.  Если вы заинтересованы в
установке CAML Light на ваш собственный компьютер, то вы должны
прочитать следующую Web-страницу для получения подробной информации:

\begin{boxed}\begin{verbatim}
  http://pauillac.inria.fr/caml/
\end{verbatim}\end{boxed}

\section{Взаимодействие с ML}

Когда ML выдает вам строку приглашения, вы можете вводить выражения,
завешаемые двумя последовательными знаками ``точка с запятой'', он
будет вычислять их и выдавать результат.  На компьютерном жаргоне
говорят, что ML находится в состоянии ``цикл read-eval-print
(считать-вычислить-напечатать)???'': выражения считываются,
вычисляются и печатаются результаты.  Например, ML может быть
использован как простой калькулятор:

\begin{boxed}\begin{verbatim}
  #10 + 5;;
  - : int = 15
\end{verbatim}\end{boxed}

Система не только возвращает ответ, но также выдает  {\em тип}
выражения, который определяется автоматически.  Система может сделать
это, поскольку знает тип встроенного оператора сложения {\tt +}.  С
другой стороны, если для выражения не может быть определен тип, то
система отвергнет его, и постарается выдать сообщение о том, почему
произошла ошибка.  В сложных случаях, сообщения об ошибках  достаточно
тяжело понять.

\begin{boxed}\begin{verbatim}
  #1 + true;;
  Toplevel input:
  >let it = 1 + true;;
  >             ^^^^
  This expression has type bool,
  but is used with type int.
\end{verbatim}\end{boxed}

Поскольку ML является функциональным языком, то выражения могут иметь
тип-функцию.  Для $lambda$-выражения $\lamb{x} t[x]$ ML предоставляет
следующий синтаксис~--- {\tt fun x -> t[x]}.  Например, мы можем
определить функцию ``следующий successor'':

\begin{boxed}\begin{verbatim}
  #fun x -> x + 1;;
  - : int -> int = <fun>
\end{verbatim}\end{boxed}

Как и в предыдущем примере, тип выражения (сейчас это {\tt int ->
  int}), выводится из выдается на экран.  Однако сама функция не
печатается; система лишь выдает {\tt <fun>}.  Это сделано потому, что
внутренее представление функций не слишком читабельно.\footnote{CAML
  не хранит их как синтаксические деревья, а компилирует в байт-код.}
Функции применяются к аргументам, также как и в $lambda$-исчислении,
путем комбинирования.  Например:

\begin{boxed}\begin{verbatim}
  #(fun x -> x + 1) 4;;
  - : int = 5
\end{verbatim}\end{boxed}

Снова, как в $lambda$-исчислении, применение функции асоциируется
слева, и вы можете написать карированные функции, используя  то же
самое соглашение по упрощению множественных $\lambda$-выражений (т.е.,
{\tt fun}-й).  Например, все следующие выражения эквивалентны:

\begin{boxed}\begin{verbatim}
  #((fun x -> (fun y -> x + y)) 1) 2;;
  - : int = 3
  #(fun x -> fun y -> x + y) 1 2;;
  - : int = 3
  #(fun x y -> x + y) 1 2;;
  - : int = 3
\end{verbatim}\end{boxed}

\section{Связывания и объявления}

It is not convenient, of course, to evaluate the whole expression in one go;
rather, we want to use {\tt let} to bind useful subexpressions to names. This
can be done as follows:

\begin{boxed}\begin{verbatim}
  #let successor = fun x -> x + 1 in
   successor(successor(successor 0));;
  - : int = 3
\end{verbatim}\end{boxed}

\noindent Function bindings may use the more elegant sugaring:

\begin{boxed}\begin{verbatim}
  #let successor x = x + 1 in
  successor(successor(successor 0));;
  - : int = 3
\end{verbatim}\end{boxed}

\noindent and can be made recursive just by adding the {\tt rec} keyword:

\begin{boxed}\begin{verbatim}
  #let rec fact n = if n = 0 then 1
                    else n * fact(n - 1) in
   fact 6;;
  - : int = 720
\end{verbatim}\end{boxed}

By using {\tt and}, we can make several binding simultaneously, and define
mutually recursive functions. For example, here are two simple, though highly
inefficient, functions to decide whether or not a natural number is odd or
even:

\begin{boxed}\begin{verbatim}
  #let rec even n = if n = 0 then true else odd (n - 1)
       and odd n  = if n = 0 then false else even (n - 1);;
  even : int -> bool = <fun>
  odd : int -> bool = <fun>
  #even 12;;
  - : bool = true
  #odd 14;;
  - : bool = false
\end{verbatim}\end{boxed}

In fact, any bindings can be performed separately from the final application.
ML remembers a set of variable bindings, and the user can add to that set
interactively. Simply omit the {\tt in} and terminate the phrase with a double
semicolon:

\begin{boxed}\begin{verbatim}
  #let successor = fun x -> x + 1;;
  successor : int -> int = <fun>
\end{verbatim}\end{boxed}

\noindent After this declaration, any later phrase may use the function {\tt
successor}, e.g:

\begin{boxed}\begin{verbatim}
  #successor 11;;
  - : int = 12
\end{verbatim}\end{boxed}

Note that we are not making {\em assignments} to {\em variables}. Each binding
is only done once when the system analyses the input; it cannot be repeated or
modified. It can be overwritten by a new definition using the same name, but
this is not assignment in the usual sense, since the sequence of events is only
connected with the {\em compilation} process, not with the dynamics of program
{\em execution}. Indeed, apart from the more interactive feedback from the
system, we could equally replace all the double semicolons after the
declarations by {\tt in} and evaluate everything at once. On this view we can
see that the overwriting of a declaration really corresponds to the definition
of a new local variable that hides the outer one, according to the usual lambda
calculus rules. For example:

\begin{boxed}\begin{verbatim}
  #let x = 1;;
  x : int = 1
  #let y = 2;;
  y : int = 2
  #let x = 3;;
  x : int = 3
  #x + y;;
  - : int = 5
\end{verbatim}\end{boxed}

\noindent is the same as:

\begin{boxed}\begin{verbatim}
  #let x = 1 in
   let y = 2 in
   let x = 3 in
   x + y;;
  - : int = 5
\end{verbatim}\end{boxed}

Note carefully that, also following lambda calculus, variable binding is {\em
static}, i.e. the first binding of {\tt x} is still used until an inner binding
occurs, and any uses of it until that point are not affected by the inner
binding. For example:

\begin{boxed}\begin{verbatim}
  #let x = 1;;
  x : int = 1
  #let f w = w + x;;
  f : int -> int = <fun>
  #let x = 2;;
  x : int = 2
  #f 0;;
  - : int = 1
\end{verbatim}\end{boxed}

The first version of LISP, however, used {\em dynamic} binding, where a
rebinding of a variable propagated to earlier uses of the variable, so that the
analogous sequence to the above would return 2. This was in fact originally
regarded as a bug, but soon programmers started to appreciate its convenience.
It meant that when some low-level function was modified, the change propagated
automatically to all applications of it in higher level functions, without the
need for recompilation. The feature survived for a long time in many LISP
dialects, but eventually the view that static binding is better prevailed. In
Common LISP, static binding is the default, but dynamic binding is available if
desired via the keyword {\tt special}.

\section{Polymorphic functions}

We can define polymorphic functions, like the identity operator:

\begin{boxed}\begin{verbatim}
  #let I = fun x -> x;;
  I : 'a -> 'a = <fun>
\end{verbatim}\end{boxed}

ML prints type variables as {\tt 'a}, {\tt 'b} etc. These are supposed to be
ASCII representations of $\alpha$, $\beta$ and so on. We can now use the
polymorphic function several times with different types:

\begin{boxed}\begin{verbatim}
  #I true;;
  - : bool = true
  #I 1;;
  - : int = 1
  #I I I I 12;;
  - : int = 12
\end{verbatim}\end{boxed}

Each instance of {\tt I} in the last expression has a different type, and
intuitively corresponds to a different function. In fact, let's define all the
combinators:

\begin{boxed}\begin{verbatim}
  #let I x = x;;
  I : 'a -> 'a = <fun>
  #let K x y = x;;
  K : 'a -> 'b -> 'a = <fun>
  #let S f g x = (f x) (g x);;
  S : ('a -> 'b -> 'c) -> ('a -> 'b) -> 'a -> 'c = <fun>
\end{verbatim}\end{boxed}

Note that the system keeps track of the types for us, even though in the last
case they were quite complicated. Now, recall that $I = S\; K\; K$; let us try
this out in ML:\footnote{We remarked that from the untyped point of view, $S\;
K\; A = I$ for any $A$. However, the reader may try, for example, $S\; K\; S$
and see that the principal type is less general than expected.}

\begin{boxed}\begin{verbatim}
  #let I' = S K K;;
  I' : '_a -> '_a = <fun>
\end{verbatim}\end{boxed}

\noindent It has the right type,\footnote{Ignore the underscores for now. This
is connected with the typing of imperative features, and we will discuss it
later.} and it may easily be checked in all concrete cases, e.g:

\begin{boxed}\begin{verbatim}
  #I' 3 = 3;;
  - : bool = true
\end{verbatim}\end{boxed}

In the above examples of polymorphic functions, the system very quickly infers
a most general type for each expression, and the type it infers is simple. This
usually happens in practice, but there are pathological cases, e.g. the
following example due to \citeN{mairson-ml}. The type of this expression takes
about 10 seconds to calculate, and occupies over 4000 lines on an 80-column
terminal.

\begin{boxed}\begin{lstlisting}
  let pair x y = fun z -> z x y in
  let x1 = fun y -> pair y y in
  let x2 = fun y -> x1(x1 y) in
  let x3 = fun y -> x2(x2 y) in
  let x4 = fun y -> x3(x3 y) in
  let x5 = fun y -> x4(x4 y) in
  x5(fun z -> z);;
\end{lstlisting}\end{boxed}

We have said that the ML programmer need never enter a type. This is true in
the sense that ML will already allocate as general a type as possible to an
expression. However it may sometimes be convenient to {\em restrict} the
generality of a type. This cannot make code work that didn't work before, but
it may serve as documentation regarding the intended purpose of the code; it is
also possible to use shorter synonyms for complicated types. Type restriction
can be achieved in ML by adding {\em type annotations} after some
expression(s). These type annotations consist of a colon followed by a type. It
usually doesn't matter exactly where these annotations are added, provided they
enforce the appropriate constraints. For example, here are some alternative
ways of constraining the identity function to type {\tt int -> int}:

\begin{boxed}\begin{verbatim}
  #let I (x:int) = x;;
  I : int -> int = <fun>
  #let I x = (x:int);;
  I : int -> int = <fun>
  #let (I:int->int) = fun x -> x;;
  I : int -> int = <fun>
  #let I = fun (x:int) -> x;;
  I : int -> int = <fun>
  #let I = ((fun x -> x):int->int);;
  I : int -> int = <fun>
\end{verbatim}\end{boxed}

\section{Эквивалентность функций}

Instead of comparing the actions of $I$ and $I'$ on particular arguments like
$3$, it would seem that we can settle the matter definitively by comparing the
functions themselves. However this doesn't work:

\begin{boxed}\begin{verbatim}
  #I' = I;;
  Uncaught exception: Invalid_argument "equal: functional value"
\end{verbatim}\end{boxed}

It is in general {\em forbidden} to compare functions for equality, though a
few special instances, where the functions are obviously the same, yield {\tt
true}:

\begin{boxed}\begin{verbatim}
  #let f x = x + 1;;
  f : int -> int = <fun>
  #let g x = x + 1;;
  g : int -> int = <fun>
  #f = f;;
  - : bool = true
  #f = g;;
  Uncaught exception: Invalid_argument "equal: functional value"
  #let h = g;;
  h : int -> int = <fun>
  #h = f;;
  Uncaught exception: Invalid_argument "equal: functional value"
  #h = g;;
  - : bool = true
\end{verbatim}\end{boxed}

Why these restrictions? Aren't functions supposed to be first-class objects in
ML? Yes, but unfortunately, (extensional) function equality is not computable.
This follows from a number of classic theorems in recursion theory, such as the
{\em unsolvability of the halting problem} and {\em Rice's
theorem}.\footnote{You will see these results proved in the Computation Theory
course. Rice's theorem is an extremely strong undecidability result which
asserts that {\em any} nontrivial property of the function corresponding to a
program is uncomputable from its text. An excellent computation theory textbook
is \citeN{davis-weyuker}.} Let us give a concrete illustration of why this
might be so. It is still an open problem whether the following function
terminates for all arguments, the assertion that it does being known as the
{\em Collatz conjecture}:\footnote{A good survey of this problem, and attempts
to solve it, is given by \citeN{lagarias-collatz}. Strictly, we should use
unlimited precision integers rather than machine arithmetic. We will see later
how to do this.}

\begin{boxed}\begin{verbatim}
  #let rec collatz n =
     if n <= 1 then 0
     else if even(n) then collatz(n / 2)
     else collatz(3 * n + 1);;
  collatz : int -> int = <fun>
\end{verbatim}\end{boxed}

What is clear, though, is that if it does halt it returns $0$. Now consider the
following trivial function:

\begin{boxed}\begin{verbatim}
  #let f (x:int) = 0;;
  f : int -> int = <fun>
\end{verbatim}\end{boxed}

By deciding the equation {\tt collatz = f}, the computer would settle the
Collatz conjecture. It is easy to concoct other examples for open mathematical
problems.

It is possible to trap out applications of the equality operator to functions
and datatypes built up from them as part of typechecking, rather than at
runtime. Types that do not involve functions in these ways are known as {\em
equality types}, since it is always valid to test objects of such types for
equality. On the negative side, this makes the type system much more
complicated. However one might argue that static typechecking should be
extended as far as feasibility allows.

\section*{Further reading}

Many books on functional programming bear on the general issues we have
discussed here, such as evaluation strategy. A good elementary introduction to
CAML Light and functional programming is \citeN{mauny-tutorial}.
\citeN{paulson-ml} is another good textbook, though based on Standard ML.

\section*{Exercises}

\begin{enumerate}

\item Suppose that a `conditional' function defined by {\tt ite(b,x,y) = if b
then x else y} is the only function available that operates on arguments of
type {\tt bool}. Is there any way to write a factorial function?

\item Use the typing rules in the last chapter to write out a formal proof that
the $S$ combinator has the type indicated by the ML system.

\item Write a simple recursively defined function to perform exponentiation of
integers, i.e. calculate $x^n$ for $n \geq 0$. Write down two ML functions, the
equality of which corresponds to the truth of Fermat's last theorem: there are
no integers $x$, $y$, $z$ and natural number $n > 2$ with $x^n + y^n = z^n$
except for the trivial case where $x = 0$ or $y = 0$.

\end{enumerate}

%%% Local Variables:
%%% TeX-master: "all"
%%% End:
