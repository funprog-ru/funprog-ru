\documentclass{fp-slides}

\begin{document}

\frame{\titlepage}
\section*{Лекция 10. Примеры на ML II.  Синтаксический анализ}

\frame{
  \frametitle{Темы}

  \begin{itemize}
  \item Задача синтаксического анализа;
    % \item The parsing problem
    \maybepause

  \item Метод рекурсивного спуска;
    % \item Recursive descent
    \maybepause

  \item Реализация синтаксических анализаторов на языке~ML;
    % \item Parsers in ML
    \maybepause

  \item Комбинаторы синтаксического анализа;
    % \item Higher order parser combinators
    \maybepause

  \item Эффективность и ограничения.
    % \item Efficiency and limitations.

  \end{itemize}
}

\frame{
  \frametitle{Грамматика языка термов}
  % \heading{Grammar for terms}

  Рассмотрим язык термов~--- выражений, в которых участвуют лишь две
  инфиксные операции: {\tt +} и~{\tt *}, а также числовые константы и
  переменные с алфавитно-цифровыми именами. Мы хотим реализовать
  синтаксический анализатор, чтобы не задавать выражения в виде
  композиции конструкторов типов.  Грамматика языка термов
  определяется множеством продукций:
  % We would like to have a parser for our terms, so that we don't
  % have to write them in terms of type constructors.
  \alert{
    \begin{eqnarray*}
      term     & \goesto & name{\verb!(!} termlist {\verb!)!}         \\
      & |       & name                                       \\
      & |       & {\verb!(!} term {\verb!)!}                 \\
      & |       & numeral                                    \\
      & |       & {\verb!-!} term                            \\
      & |       & term {\verb! + !} term                     \\
      & |       & term {\verb! * !} term                     \\
      termlist & \goesto & term {\verb!,!} termlist                   \\
      & |       & term
    \end{eqnarray*}}

  Таким образом, грамматика языка термов определяется множеством
  продукций.

  % Here we have a grammar for terms, defined by a set of production rules.
}

\frame{
  \frametitle{Неоднозначность}

  % \heading{Ambiguity}



  Задача {\em синтаксического анализа (разбора)}, в целом, является обратной
  рассмотренной ранее задаче составления грамматики. Цель синтаксического 
  анализа~--- найти последовательность применения продукций, порождающую
  данную строку.

  % The task of {\em parsing}, in general, is to reverse this, i.e. find a sequence
  % of productions that could generate a given string.

  К сожалению, наша грамматика является {\em неоднозначной}, поскольку некоторые
  строки могут порождаться различными путями, например
  % Unfortunately the above grammar is {\em ambiguous}, since certain strings can
  % be produced in several ways, e.g.
  \alert{
    \begin{eqnarray*}
      term     & \goesto & term {\verb! + !} term                             \\
      & \goesto & term {\verb! + !} term {\verb! * !} term
    \end{eqnarray*}}%
  и
  \alert{
    \begin{eqnarray*}
      term     & \goesto & term {\verb! * !} term                             \\
      & \goesto & term {\verb! + !} term {\verb! * !} term
    \end{eqnarray*}}%
  Различный порядок применения продукций соответствует различным 
  <<деревьям разбора>>. На самом деле, мы вправе трактовать
  \alert{$x {\verb! + !} y {\verb! * !} z$} 
  как~\alert{$x {\verb! + !} (y {\verb! * !} z)$} 
  либо как~\alert{$(x {\verb! + !} y) {\verb! * !} z$}.
  % These correspond to different <<parse trees>>. Effectively, we are free to
  % interpret \alert{$x {\verb! + !} y {\verb! * !} z$} either as \alert{$x
  %   {\verb! + !} (y {\verb! * !} z)$} or \alert{$(x {\verb! + !} y) {\verb! * !}
  %   z$}.

}

\frame{
  \frametitle{Назначение приоритетов}

  % \heading{Encoding precedences}



  Приоритеты операций могут быть выражены путём введения дополнительных
  категорий, например
  % We can encode operator precedences by introducing extra categories, e.g.
  \alert{
    \begin{eqnarray*}
      atom     & \goesto & name{\verb!(!} termlist {\verb!)!}         \\
      & |       & name                                       \\
      & |       & numeral                                    \\
      & |       & {\verb!(!} term {\verb!)!}                 \\
      & |       & {\verb!-!} atom                            \\
      mulexp   & \goesto & atom {\verb! * !} mulexp                   \\
      & |       & atom                                       \\
      term     & \goesto & mulexp {\verb! + !} term                   \\
      & |       & mulexp                                     \\
      termlist & \goesto & term {\verb!,!} termlist                   \\
      & |       & term
    \end{eqnarray*}}%
  Такая грамматика однозначна. Операция умножения имеет больший приоритет,
  чем сложение; обе операции правоассоциативны.
  % Now it's unambiguous. Multiplication has higher precedence and both infixes
  % associate to the right.

}

\frame{
  \frametitle{Метод рекурсивного спуска}

  % \heading{Recursive descent}



  Синтаксический анализатор, реализующий метод рекурсивного спуска, представляет
  собой множество взаимно рекурсивных функций, прямо сопоставленных каждой
  синтаксической категории ($term$, $mulexp$ и~т.~д.).
  % A {\em recursive descent} parser is a series of mutually recursive functions,
  % one for each syntactic category ($term$, $mulexp$ etc.).

  Структура рекурсивных зависимостей при этом соответствует структуре грамматики.
  % The mutually recursive structure mirrors that in the grammar.

  Это соответствие обеспечивает достаточно лёгкий и естественный способ реализации
  подобных анализаторов, особенно на языке~ML, для которого рекурсия представляет
  собой основной механизм управления порядком действий.
  % This makes them quite easy and natural to write --- especially in ML, where
  % recursion is the principal control mechanism.

  Например, процедура анализа термов {\black \verb!term!} при появлении во 
  входном потоке символа {\black \verb!-!} будет рекурсивно вызывать себя для
  анализа аргумента операции, а обнаружив имя, за которым следует
  открывающая скобка, осуществит вызов~{\black \verb!termlist!}.
  В свою очередь, эта процедура вызовет~{\black \verb!term!} не менее одного раза,
  и так далее.
  % For example, the procedure for parsing terms, say {\black \verb!term!} will, on
  % encountering a {\black \verb!-!} symbol, make a recursive call to itself to
  % parse the subterm, and on encountering a name followed by an opening
  % parenthesis, will make a recursive call to {\black \verb!termlist!}. This in
  % itself will make at least one recursive call to {\black \verb!term!}, and so
  % on.

}

\frame{
  \frametitle{Реализация синтаксического анализа на языке~ML}

  % \heading{Parsers in ML}



  Предположим, что синтаксический анализатор принимает список входных
  символов или лексем (токенов) произвольного типа.
  % We assume that a parser accepts a list of input characters or tokens of
  % arbitrary type.

  Результатом его работы является значение некоторого произвольного типа, 
  а также список входных объектов, которые не были ещё обработаны. Следовательно,
  тип анализатора
  % It returns the result of parsing, which has some other arbitrary type, and also
  % the list of input objects not yet processed. Therefore the type of a parser is:
  % 
  \alert{$$ (\alpha)list \to \beta \times (\alpha)list $$}%
  % 
  Например, для заданной входной строки символов {\black \verb!(x + y) * z!}
  функция~{\black \verb!atom!} обработает подстроку~{\black \verb!(x + y)!} 
  и вернёт нераспознанные символы~{\black \verb!* z!}. Также она может вернуть
  дерево разбора обработанной подстроки в виде значения рекурсивного типа,
  определённого ранее. Таким образом, мы в итоге получим 
  % For example, when given the input characters {\black \verb!(x + y) * z!} the
  % function {\black \verb!atom!} will process the characters {\black \verb!(x + y)!} 
  % and leave the remaining characters {\black \verb!* z!}. It might return a
  % parse tree for the processed expression using our earlier recursive type, and
  % hence we would have:
  % 
  \begin{black}\begin{verbatim}
  atom "(x + y) * z" =
    Fn("+",[Var "x"; Var "y"]),"* z"
\end{verbatim}\end{black}

}

\frame{
  \frametitle{Комбинаторы синтаксического анализа}

  % \heading{Parser combinators}



  Используя язык~ML, мы можем определить набор {\em комбинаторов}, при помощи
  которых будем совместно использовать различные синтаксические анализаторы 
  и создавать новые на базе уже имеющихся.
  % In ML, we can define a series of {\em combinators} for plugging parsers
  % together and creating new parsers from existing ones.

  Определив некоторые из них как инфиксные операции, мы в состоянии придать
  программе синтаксического анализа вид, весьма схожий со структурой
  самой грамматики.
  % By giving some of them infix status, we can make the ML parser program look
  % quite similar in structure to the original grammar.

  Для начала введём исключение, сигнализирующее об ошибках анализа:
  % First we declare an exception to be used where parsing fails:
  \begin{black}\begin{verbatim}
  exception Noparse;;
\end{verbatim}\end{black}
  Далее определим операцию {\black \verb!p1 ++ p2!}, которая вначале применяет
  {\black \verb!p1!}, затем~--- {\black \verb!p2!} к оставшимся лексемам;
  а также {\black \verb!many!}, применяющую заданный анализатор максимально 
  возможное количество раз.
  % {\black \verb!p1 ++ p2!} applies {\black \verb!p1!} first and then applies
  % {\black \verb!p2!} to the remaining tokens; {\black \verb!many!} keeps applying
  % the same parser as long as possible.

  {\black \verb!p >> f!} работает аналогично {\black \verb!p!}, но затем 
  применяет {\black\verb!f!} к результату анализа.
  % {\black \verb!p >> f!} works like {\black \verb!p!} but then applies {\black
  %   \verb!f!} to the result of the parse.

  {\black \verb!p1 || p2!} делает попытку применить {\black \verb!p1!}, а затем,
  в случае ошибки~--- {\black \verb!p2!}. Все эти операции автоматически 
  считаются инфиксными с приоритетами по убыванию.
  % {\black \verb!p1 || p2!} tries {\black \verb!p1!} first, and if that fails,
  % tries {\black \verb!p2!}. These are automatically infix, in decreasing order of
  % precedence.

}

\frame{
  \frametitle{Определение комбинаторов}

  % \heading{Definitions of the combinators}



  \begin{black}\begin{verbatim}
let prefix ++ parser1 parser2 input =
  let result1,rest1 = parser1 input in
  let result2,rest2 = parser2 rest1 in
  (result1,result2),rest2;;

let rec many parser input =
  try let result,next = parser input in
      let results,rest = many parser next in
      (result::results),rest
  with Noparse -> [],input;;

let prefix >> parser treatment input =
  let result,rest = parser input in
  treatment(result),rest;;

let prefix || parser1 parser2 input =
  try parser1 input
  with Noparse -> parser2 input;;
\end{verbatim}\end{black}

}

\frame{
  \frametitle{Вспомогательные функции}

  % \heading{Auxiliary functions}



  Введём следующие универсальные функции, которыми воспользуемся в дальнейшем:
  % These are the general functions we will use:
  \begin{black}\begin{verbatim}
let rec itlist f =
     fun [] b -> b
       | (h::t) b -> f h (itlist f t b);;

let uncurry f(x,y) = f x y;;
let K x y = x;;
let C f x y = f y x;;

let o f g x = f(g x);;
#infix "o";;

let explode s =
  let rec exap n l =
    if n < 0 then l else
    exap (n - 1) ((sub_string s n 1)::l) in
  exap (string_length s - 1) [];;
\end{verbatim}\end{black}

}

\frame{
  \frametitle{Элементарные анализаторы}

  % \heading{Atomic parsers}



  Для начала, определим несколько примитивных синтаксических анализаторов:
  % We need a few primitive parsers to get us started.

  \begin{black}\begin{verbatim}
  let some p =
    fun [] -> raise Noparse
      | (h::t) -> if p h then (h,t)
                  else raise Noparse;;

  let a tok =
    some (fun item -> item = tok);;

  let finished input =
    if input = [] then 0,input
    else raise Noparse;;
\end{verbatim}\end{black}

  Первые два принимают очередной символ входной последовательности, если он 
  удовлетворяет условию~{\black \verb!p!} или равен {\black \verb!tok!}
  соответственно. Третий примитив гарантирует, что вся входная последовательность
  была обработана. 

  % The first two accept something satisfying {\black \verb!p!}, and something
  % equal to {\black \verb!tok!}, respectively. The last one makes sure there is no
  % unprocessed input.

}

\frame{
  \frametitle{Лексический анализ}

  % \heading{Lexical analysis}



  Для начала нам потребуется провести лексический анализ, т.~е.\ разбить
  входную последовательность символов на лексемы (токены). Это также возможно
  сделать, используя наши комбинаторы в сочетании с несколькими функциями
  классификации символов. Прежде всего, определим тип, представляющий лексемы:
  % First we want to do lexical analysis, i.e. split the input characters into
  % tokens. This can also be done using our combinators, together with a few
  % character discrimination functions. First we declare the type of tokens:
  % 
  \begin{black}\begin{verbatim}
  type token = Name of string
             | Num of string
             | Other of string;;
\end{verbatim}\end{black}

  Нам требуется, чтобы лексический анализатор принимал строку и возвращал
  соответствующий ей список лексем, игнорируя пробелы, например:
  % We want the lexer to accept a string and produce a list of tokens, ignoring
  % spaces, e.g.
  \begin{black}\begin{footnotesize}\begin{verbatim}
  #lex "sin(x + y) * cos(2 * x + y)";;
   - : token list =
   [Name "sin"; Other "("; Name "x"; Other "+";
    Name "y"; Other ")"; Other "*"; Name "cos";
    Other "("; Num "2"; Other "*"; Name "x";
    Other "+"; Name "y"; Other ")"]
\end{verbatim}\end{footnotesize}\end{black}

}

\frame{
  \frametitle{Реализация лексического анализатора}

  % \heading{Definition of the lexer}



  \begin{black}\begin{footnotesize}\begin{verbatim}
let lex =
  let several p = many (some p) in
  let lowercase_letter s = "a" <= s & s <= "z" in
  let uppercase_letter s = "A" <= s & s <= "Z" in
  let letter s =
    lowercase_letter s or uppercase_letter s in
  let alpha s = letter s or s = "_" or s = "'" in
  let digit s = "0" <= s & s <= "9" in
  let alphanum s = alpha s or digit s in
  let space s = s = " " or s = "\n" or s = "\t" in
  let collect(h,t) = h^(itlist (prefix ^) t "") in
  let rawname =
     some alpha ++ several alphanum
     >> (Name o collect) in
  let rawnumeral =
     some digit ++ several digit
     >> (Num o collect) in
  let rawother = some (K true) >> Other in
  let token =
    (rawname || rawnumeral || rawother) ++
    several space >> fst in
  let tokens = (several space ++ many token) >> snd in
  let alltokens = (tokens ++ finished) >> fst in
  fst o alltokens o explode;;
\end{verbatim}\end{footnotesize}\end{black}

}

\frame{
  \frametitle{Анализатор термов}

  % \heading{Parsing terms}



  Реализацию анализа языка термов начнем с определения базовых анализаторов
  отдельных лексем заданного класса:
  % In order to parse terms, we start with some basic parsers for single tokens of
  % a particular kind:
  % 
  \begin{black}\begin{verbatim}
  let name =
    fun (Name s::rest) -> s,rest
      | _ -> raise Noparse;;

  let numeral =
    fun (Num s::rest) -> s,rest
      | _ -> raise Noparse;;

  let other =
    fun (Other s::rest) -> s,rest
      | _ -> raise Noparse;;
\end{verbatim}\end{black}

  С помощью этих функций мы можем определить анализатор термов в виде, очень
  схожем с исходной грамматикой. Основное различие состоит в том, что каждой
  продукции сопоставлено некоторое действие, результат которого возвращается
  как результат анализа.
  % Now we can define a parser for terms, in a form very similar to the original
  % grammar. The main difference is that each production rule has associated with
  % it some sort of special action to take as a result of parsing.

}

\frame{
  \frametitle{Анализатор термов (вариант~1)}

  % \heading{The term parser (take 1)}

  \begin{black}\begin{footnotesize}\begin{verbatim}
let rec atom input
     = (name ++
        a (Other "(") ++ termlist ++ a (Other ")")
            >> (fun (((f,_),a),_) -> Fn(f,a))
     || name
            >> (fun s -> Var s)
     || numeral
            >> (fun s -> Const s)
     || a (Other "(") ++ term ++ a (Other ")")
            >> (snd o fst)
     || a (Other "-") ++ atom
            >> snd) input
and mulexp input
     = (atom ++ a(Other "*") ++ mulexp
            >> (fun ((a,_),m) -> Fn("*",[a;m]))
     || atom) input
and term input
     = (mulexp ++ a(Other "+") ++ term
            >> (fun ((a,_),m) -> Fn("+",[a;m]))
     || mulexp) input
and termlist input
     = (term ++ a (Other ",") ++ termlist
            >> (fun ((h,_),t) -> h::t)
     || term
            >> (fun h -> [h])) input;;
\end{verbatim}\end{footnotesize}\end{black}

}

\frame{
  \frametitle{Примеры}

  % \heading{Examples}

  Объединим определённые ранее примитивы в единую функцию: 
  % Let us package everything up as a single parsing function:
  % 
  \begin{black}\begin{verbatim}
let parser =
  fst o (term ++ finished >> fst) o lex;;
\end{verbatim}\end{black}
  % 
  Наглядной иллюстрацией работы этой функции является её вызов до и после
  установки специализированной функции вывода (см.\ выше):
  % \noindent To see it in action, we try with and without the printer
  % (see above) installed:
  % 
  \begin{black}\begin{footnotesize}\begin{verbatim}
  #parser "sin(x + y) * cos(2 * x + y)";;
  - : term =
   Fn
    ("*",
     [Fn ("sin", [Fn ("+", [Var "x"; Var "y"])]);
      Fn ("cos", [Fn ("+", [Fn ("*", [Const "2";
                                      Var "x"]);
                            Var "y"])])])
  #install_printer "print_term";;
  - : unit = ()
  #parser "sin(x + y) * cos(2 * x + y)";;
  - : term = <<sin(x + y) * cos(2 * x + y)`
\end{verbatim}\end{footnotesize}\end{black}

}

\frame{
  \frametitle{Автоматический учёт приоритетов}

  % heading{Automating precedence parsing}

  Возможности языка~ML позволяют на основе динамического списка
  инфиксных операций легко сконструировать <<исправленную>> с их
  учётом версию грамматики.

  % We can easily let ML construct the `fixed-up>> grammar from our
  % dynamic list of infixes:

\begin{black}\begin{footnotesize}\begin{verbatim}
let rec binop op parser input =
  let atom1,rest1 as result = parser input in
  if not rest1 = [] & hd rest1 = Other op then
    let atom2,rest2 = binop op parser (tl rest1) in
    Fn(op,[atom1; atom2]),rest2
  else result;;

let findmin l = itlist
  (fun (_,pr1 as p1) (_,pr2 as p2) ->
     if pr1 <= pr2 then p1 else p2) (tl l) (hd l);;

let rec delete x (h::t) =
  if h = x then t else h::(delete x t);;

let rec precedence ilist parser input =
  if ilist = [] then parser input else
  let opp = findmin ilist in
  let ilist' = delete opp ilist in
  binop (fst opp) (precedence ilist' parser) input;;
\end{verbatim}\end{footnotesize}\end{black}

  Использование этой функции в основном анализаторе делает его более
  простым и более общим.
  % By using this function, we can make the main parser simpler and
  % more general.
}

\frame{
  \frametitle{Анализатор термов (вариант~2)}

  % \heading{The term parser (take 2)}

  \begin{black}\begin{footnotesize}\begin{verbatim}
let rec atom input
     = (name ++
        a (Other "(") ++ termlist ++ a (Other ")")
            >> (fun (((f,_),a),_) -> Fn(f,a))
     || name
            >> (fun s -> Var s)
     || numeral
            >> (fun s -> Const s)
     || a (Other "(") ++ term ++ a (Other ")")
            >> (snd o fst)
     || a (Other "-") ++ atom
            >> snd) input
and term input = precedence (!infixes) atom input
and termlist input
     = (term ++ a (Other ",") ++ termlist
            >> (fun ((h,_),t) -> h::t)
     || term
            >> (fun h -> [h])) input;;
\end{verbatim}\end{footnotesize}\end{black}

  Эти определения дают возможность динамического конструирования
  анализатора с учётом приоритетов на основе списка инфиксных операций в
  том виде, в котором он существует в момент обращения к нему. Базовая
  грамматика упрощается.

  % This will dynamically construct the precedence parser using the list
  % of infixes active when it is actually used. Now the basic grammar is
  % simpler.

}

\frame{
  \frametitle{Возврат и повторное сканирование}

  % \heading{Backtracking and reprocessing}



  Некоторые продукции в рамках одной и той же синтаксической категории могут
  иметь общий префикс. Например, таким свойством обладают правила вывода~$term$:
  % Some productions for the same syntactic category have a common
  % prefix. Note that our production rules for $term$ have this property:
  \alert{
    \begin{eqnarray*}
      term     & \goesto & name{\verb!(!} termlist {\verb!)!}         \\
      & |       & name                                       \\
      & |       & \cdots
    \end{eqnarray*}}%
  В нашей реализации более длинная продукция целенаправленно обрабатывается
  первой, так как успешное чтение имени может привести к проблемам с дальнейшим
  разбором списка аргументов.
  % We carefully put the longer production first in our actual implementation,
  % otherwise success in reading a name would cause the abandonment of attempts to
  % read a parenthesized list of arguments.

  Однако, при необходимости возврата (первая альтернатива оказалась неприменимой),
  разбор имени будет проведен дважды.
  % However, this backtracking can lead to our processing the initial name twice.

  В данной продукции это не приводит к серьезным потерям эффективности, но 
  может привести при обработке~{\black \tt termlist}.
  % This is not very serious here, but it could be in {\black \tt termlist}.

}

\frame{
  \frametitle{Устранение избыточности}

  % \heading{An improved treatment}



  Заменим
  % We can easily replace:
  % 
  \begin{black}\begin{verbatim}
let ...
and termlist input
     = (term ++ a (Other ",") ++ termlist
            >> (fun ((h,_),t) -> h::t)
     || term
            >> (fun h -> [h])) input;;
\end{verbatim}\end{black}%
  на
  % \noindent with
  \begin{black}\begin{verbatim}
let ...
and termlist input
    = term ++
      many (a (Other ",") ++ term >> snd)
            >> (fun (h,t) -> h::t) input;;
\end{verbatim}\end{black}%
  получив очередную реализацию, которая будет и проще, и эффективнее.
  Окончательный вариант анализатора выглядит так:
  % \noindent This gives another improvement to the parser, which is now more
  % efficient and slightly simpler. The final version is:

}

\frame{
  \frametitle{Анализатор термов (вариант~3)}

  % \heading{The term parser (take 3)}



  \begin{black}\begin{footnotesize}\begin{verbatim}
let rec atom input
     = (name ++
        a (Other "(") ++ termlist ++ a (Other ")")
            >> (fun (((f,_),a),_) -> Fn(f,a))
     || name
            >> (fun s -> Var s)
     || numeral
            >> (fun s -> Const s)
     || a (Other "(") ++ term ++ a (Other ")")
            >> (snd o fst)
     || a (Other "-") ++ atom
            >> snd) input
and term input = precedence (!infixes) atom input
and termlist input
      = (term ++ many (a (Other ",") ++ term >> snd)
            >> (fun (h,t) -> h::t)) input;;
\end{verbatim}\end{footnotesize}\end{black}

}

\frame{
  \frametitle{Общие замечания}

  % \heading{General remarks}



  Рассмотренный метод синтаксического анализа может с разумной осторожностью
  эффективно использоваться в различных приложениях. Он служит хорошей 
  иллюстрацией обширных возможностей функций высших порядков.
  % With care, this parsing method can be used effectively. It is a good
  % illustration of the power of higher order functions.

  Код анализатора тщательно структурирован и соответствует грамматике,
  что обеспечивает лёгкость его модификации.
  % The code of such a parser is highly structured and similar to the grammar,
  % therefore easy to modify.

  Однако, он не так эффективен, как хорошие LR-анализаторы, в частности те,
  которые могут быть автоматически сгенерированы CAML-Yacc.
  % However it is not as efficient as LR parsers; CAML-Yacc is capable of
  % generating good LR parsers automatically.

  Ещё одним ограничением метода рекурсивного спуска являются проблемы с
  обработкой {\em левосторонней рекурсии} в продукциях. Например, если бы
  мы попытались сделать левоассоциативной операцию сложения, определённую в 
  рассмотренных ранее примерах, это можно было бы выразить так:
  % Recursive descent also has trouble with {\em left recursion}. For example, if
  % we had wanted to make the addition operator left-associative in our earlier
  % grammar, we could have used:
  \alert{
    \begin{eqnarray*}
      term     & \goesto & term {\verb! + !} mulexp                   \\
      & |       & mulexp
    \end{eqnarray*}}
  Прямолинейный перевод этого правила на язык~ML при исполнении зацикливается. 
  Однако, зачастую подобные конструкции легко заменяются соответствующим 
  итерированием.
  % The naive transcription into ML would loop indefinitely. However we can often
  % replace such constructs with explicit repetitions.


}

\end{document}

%%% Local Variables:
%%% TeX-master: "all"
%%% End:
